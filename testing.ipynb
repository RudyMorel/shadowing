{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from shadowing import (\n",
    "    RelativeMSE, Foveal, PathShadowing, PredictionContext, \n",
    "    realized_variance, ArrayType\n",
    ")\n",
    "\n",
    "def _torch(x: ArrayType) -> torch.Tensor:\n",
    "    \"\"\" Convert x to a torch float tensor. \"\"\"\n",
    "    if isinstance(x, torch.Tensor):\n",
    "        return x\n",
    "    return torch.tensor(x, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PathDistance\n",
    "distance = RelativeMSE()\n",
    "\n",
    "x = torch.randn(8,34)\n",
    "y = torch.randn(128,512,34)\n",
    "\n",
    "ds1, idces1 = distance.forward_topk(x, y, k=32, n_splits=32)\n",
    "ds2, idces2 = distance.forward_topk(x, y, k=64, n_splits=64)\n",
    "\n",
    "assert torch.equal(ds1, ds2[:,:ds1.shape[1]])\n",
    "assert torch.equal(idces1, idces2[:,:idces1.shape[1],:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shadowing correctly select paths\n",
    "x_context = torch.randn(8, 1, 126)\n",
    "x_dataset = torch.randn(32, 1, 4096)\n",
    "embedding = Foveal(alpha=1.15, beta=0.9, max_context=126)\n",
    "distance = RelativeMSE()\n",
    "obj = PathShadowing(embedding, distance, x_dataset, context=PredictionContext(horizon=252))\n",
    "distances, paths = obj.shadow(x_context, n_splits=1, k=1024, cuda=False)\n",
    "\n",
    "# re-compute the distance\n",
    "paths = _torch(paths)\n",
    "paths = obj.context.select_in_context(paths)\n",
    "paths = embedding(paths.view(-1, *paths.shape[2:]))\n",
    "paths = paths.view(*distances.shape, -1)\n",
    "x_context = _torch(x_context)\n",
    "x_context = embedding(x_context)\n",
    "ds_test = distance(x_context, paths)\n",
    "assert torch.allclose(ds_test, _torch(distances), rtol=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.29s/it]\n"
     ]
    }
   ],
   "source": [
    "# execution time\n",
    "x_context = torch.randn(1, 1, 126)\n",
    "x_dataset = torch.randn(131072, 1, 4096)\n",
    "embedding = Foveal(alpha=1.15, beta=0.9, max_context=126)\n",
    "distance = RelativeMSE()\n",
    "obj = PathShadowing(embedding, distance, x_dataset, context=PredictionContext(horizon=252))\n",
    "to_predict = lambda x: realized_variance(x, Ts=[2,7,252], vol=False)\n",
    "pred, pred_std = obj.predict(x_context, k=10000, to_predict=to_predict, eta=0.1,\n",
    "                             n_context_splits=1, n_dataset_splits=8, cuda=True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
